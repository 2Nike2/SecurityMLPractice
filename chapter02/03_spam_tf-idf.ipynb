{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットのダウンロード\n",
    "https://github.com/oreilly-japan/ml-security-jp/blob/master/ch02/enron1.zip  \n",
    "を取得して同じディレクトリに格納して、解凍する。  \n",
    "enron1  \n",
    "├── ham  \n",
    "├── spam  \n",
    "└── Summary.txt  \n",
    "といった配置になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "import os\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import optuna.integration.lightgbm as olgb\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lists(folder):\n",
    "    key_list = []\n",
    "    file_list = os.listdir(folder)\n",
    "    for filename in file_list:\n",
    "        f = codecs.open(folder + filename, 'r', encoding='utf-8', errors='ignore')\n",
    "        key_list.append(f.read())\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    return key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mails = list()\n",
    "spam = init_lists('./enron1/spam/')\n",
    "ham = init_lists('./enron1/ham/')\n",
    "\n",
    "all_mails = [(mail, '1') for mail in spam]\n",
    "all_mails +=[(mail, '0') for mail in ham]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_mails, columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X = tfidf.fit_transform(df['text'])\n",
    "column_names = tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.toarray())\n",
    "X = X.astype(float)\n",
    "X.columns = column_names\n",
    "y = df['label'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = olgb.Dataset(X_train, y_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt'\n",
    "}\n",
    "\n",
    "tuner = olgb.LightGBMTunerCV(params, train, num_boost_round=100)\n",
    "\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score:', 1 - tuner.best_score)\n",
    "best_params = tuner.best_params\n",
    "\n",
    "print('Best params:')\n",
    "for key, value in best_params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': best_params['lambda_l1'],\n",
    "    'lambda_l2': best_params['lambda_l2'],\n",
    "    'num_leaves': best_params['num_leaves'],\n",
    "    'feature_fraction': best_params['feature_fraction'],\n",
    "    'bagging_fraction': best_params['bagging_fraction'],\n",
    "    'bagging_freq': best_params['bagging_freq'],\n",
    "    'min_child_samples': best_params['min_child_samples']\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, train_data, num_boost_round=100, verbose_eval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gbm.predict(X_test)\n",
    "pred_labels  = np.rint(preds)\n",
    "\n",
    "print('正解率: {:.5f}%'.format(100 * accuracy_score(y_test, pred_labels)))\n",
    "print(confusion_matrix(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(gbm, figsize=(12, 6), max_num_features=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_rows = (df.label == '1')\n",
    "spam_data = df[spam_rows]\n",
    "\n",
    "count = 0\n",
    "for i in spam_data['text']:\n",
    "    count = count + i.count('subject')\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_rows = (df.label == '0')\n",
    "legit_data = df[legit_rows]\n",
    "\n",
    "count = 0\n",
    "for i in legit_data['text']:\n",
    "    count = count + i.count('subject')\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
