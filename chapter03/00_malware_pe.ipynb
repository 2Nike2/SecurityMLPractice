{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットのダウンロード\n",
    "https://github.com/oreilly-japan/ml-security-jp/blob/master/ch03/MalwareData.csv.gz  \n",
    "を取得して同じディレクトリに格納し、解凍を行う。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn import model_selection\n",
    "import ydata_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MalwareDataset = pd.read_csv('MalwareData.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata_profiling.ProfileReport(df=MalwareDataset, minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.hist(MalwareDataset.loc[MalwareDataset['legitimate'] == 1, 'VersionInformationSize'], range=(0, 26), alpha=0.5, label='1')\n",
    "plt.hist(MalwareDataset.loc[MalwareDataset['legitimate'] == 0, 'VersionInformationSize'], range=(0, 26), alpha=0.5, label='0')\n",
    "\n",
    "plt.legend(title='legitimate')\n",
    "plt.xlim(0, 26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(MalwareDataset.loc[MalwareDataset['legitimate'] == 1, 'MajorSubsystemVersion'], range=(0, 10), alpha=0.5, label='1')\n",
    "plt.hist(MalwareDataset.loc[MalwareDataset['legitimate'] == 0, 'MajorSubsystemVersion'], range=(0, 10), alpha=0.5, label='0')\n",
    "\n",
    "plt.legend(title='legitimate')\n",
    "plt.xlim(2, 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MalwareDataset.drop(['Name', 'md5', 'legitimate'], axis='columns')\n",
    "y = MalwareDataset['legitimate']\n",
    "FeatSelect = ExtraTreesClassifier().fit(X, y)\n",
    "Model = SelectFromModel(FeatSelect, prefit=True)\n",
    "feature_idx = Model.get_support()\n",
    "feature_name = X.columns[feature_idx]\n",
    "X = Model.transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "X.columns = feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = X.shape[1]\n",
    "FI = ExtraTreesClassifier().fit(X, y).feature_importances_\n",
    "Index = np.argsort(FI)[::-1][:Features]\n",
    "for feat in range(Features):\n",
    "    print(\"Feature: {} Importance: {:.5f}\".format(MalwareDataset.columns[2+Index[feat]].ljust(30), FI[Index[feat]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective_RF:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __call__(self, trial):\n",
    "        criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "        # max_features = trial.suggest_int('max_features', ['auto', 'sqrt', 'log2'])\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 5)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "        \n",
    "        model = RandomForestClassifier(\n",
    "            criterion=criterion,\n",
    "            bootstrap=bootstrap,\n",
    "            # max_features=max_features,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf\n",
    "        )\n",
    "        \n",
    "        scores = cross_validate(model, self.X, self.y, cv=5, n_jobs=-1)\n",
    "        \n",
    "        return scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = Objective_RF(X_train, y_train)\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, timeout=60)\n",
    "print('params:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    criterion=study.best_params['criterion'],\n",
    "    bootstrap=study.best_params['bootstrap'],\n",
    "    # max_features=study.best_params['max_features'],\n",
    "    min_samples_split=study.best_params['min_samples_split'],\n",
    "    min_samples_leaf=study.best_params['min_samples_leaf']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('正解率: {:.5f} %'.format(100 * accuracy_score(y_test, pred)))\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=True)\n",
    "\n",
    "feat_importances.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective_GBC:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __call__(self, trial):\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "        max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
    "        learning_rate = float(trial.suggest_loguniform('learning_rate', 1e-2, 1e-0))\n",
    "        criterion = trial.suggest_categorical('criterion', ['friedman_mse', 'squared_error'])\n",
    "        \n",
    "        model = GradientBoostingClassifier(\n",
    "            max_depth=max_depth,\n",
    "            max_features=max_features,\n",
    "            learning_rate=learning_rate,\n",
    "            criterion=criterion\n",
    "        )\n",
    "        \n",
    "        scores = cross_validate(model, self.X, self.y, cv=5, n_jobs=-1)\n",
    "        \n",
    "        return scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = Objective_GBC(X_test, y_test)\n",
    "study = optuna.create_study()\n",
    "\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "print('params:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(\n",
    "    max_depth=study.best_params['max_depth'],\n",
    "    max_features=study.best_params['max_features'],\n",
    "    learning_rate=study.best_params['learning_rate'],\n",
    "    criterion=study.best_params['criterion']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('正解率: {:.5f} %'.format(100 * accuracy_score(y_test, pred)))\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=True)\n",
    "feat_importances.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective_ABC:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __call__(self, trial):\n",
    "        \n",
    "        algorithm = trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R'])\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 1e-2, 1e-0)\n",
    "        \n",
    "        model = AdaBoostClassifier(\n",
    "            algorithm=algorithm,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "        \n",
    "        scores = cross_validate(model, self.X, self.y, cv=5, n_jobs=-1)\n",
    "        return scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = Objective_ABC(X_train, y_train)\n",
    "study = optuna.create_study()\n",
    "\n",
    "study.optimize(objective, timeout=60)\n",
    "\n",
    "print('params:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(\n",
    "    algorithm=study.best_params['algorithm'],\n",
    "    learning_rate=study.best_params['learning_rate']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('正解率: {:.5f} %'.format(100 * accuracy_score(y_test, pred)))\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=True)\n",
    "feat_importances.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
