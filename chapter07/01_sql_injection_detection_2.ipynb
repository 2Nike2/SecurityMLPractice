{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import optuna.integration.lightgbm as olgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./HttpParamsDataset/payload_train.csv')\n",
    "test_data = pd.read_csv('./HttpParamsDataset/payload_test.csv')\n",
    "\n",
    "train_rows = ((df.attack_type == 'norm') | (df.attack_type == 'sqli'))\n",
    "df = df[train_rows]\n",
    "\n",
    "test_train_rows = ((test_data.attack_type == 'norm') | (test_data.attack_type == 'sqli'))\n",
    "test_data = test_data[test_train_rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df[['label']]\n",
    "test_y = test_data[['label']]\n",
    "\n",
    "df_x = df.iloc[:, :-1]\n",
    "test_x = test_data.iloc[:, :-1]\n",
    "\n",
    "X_all = pd.concat([df_x, test_x])\n",
    "y_all = pd.concat([df_y, test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = y_all.label.replace({'norm': 0, 'anom': 1})\n",
    "y_all = y_all.assign(label=rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all['payload']\n",
    "y = y_all\n",
    "\n",
    "vec_opts = {\n",
    "    'ngram_range': (1, 1),\n",
    "    'analyzer': 'char',\n",
    "    'min_df': 0.1\n",
    "}\n",
    "v = TfidfVectorizer(**vec_opts)\n",
    "\n",
    "X = v.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = v.get_feature_names_out()\n",
    "np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.toarray())\n",
    "df.columns = features\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=101)\n",
    "\n",
    "train = olgb.Dataset(X_train, y_train)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}\n",
    "\n",
    "tuner = olgb.LightGBMTunerCV(params, train)\n",
    "\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score:', tuner.best_score)\n",
    "best_params = tuner.best_params\n",
    "print('Best params:', best_params)\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"       {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': best_params['lambda_l1'],\n",
    "    'lambda_l2': best_params['lambda_l2'],\n",
    "    'num_leaves': best_params['num_leaves'],\n",
    "    'feature_fraction': best_params['feature_fraction'],\n",
    "    'bagging_fraction': best_params['bagging_fraction'],\n",
    "    'bagging_freq': best_params['bagging_freq'],\n",
    "    'min_child_samples': best_params['min_child_samples']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=100,\n",
    "    verbose_eval=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gbm.predict(X_test)\n",
    "pred_labels = np.rint(preds)\n",
    "\n",
    "print('Accuracy: {:.5f} %'.format(100 * accuracy_score(y_test, pred_labels)))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
