{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_mnist, preprocess\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd\n",
    "from art.defences.detector.poison import ActivationDefence\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw), min_pixel_value, max_pixel_value = load_mnist(raw=True)\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = np.max(X_train_raw)\n",
    "def add_modification(x):\n",
    "    return add_pattern_bd(x, pixel_value=max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_dataset(X_clean, y_clean, percent_poison, poison_func):\n",
    "    X_poison = np.copy(X_clean)\n",
    "    y_poison = np.copy(y_clean)\n",
    "    is_poison = np.zeros_like(y_poison)\n",
    "\n",
    "    sources = np.arange(nb_classes)\n",
    "    targets = (np.arange(nb_classes) + 1) % nb_classes\n",
    "\n",
    "    for i, (src, tgt) in enumerate(zip(sources, targets)):\n",
    "        n_points_in_tgt = np.size(np.where(y_clean == tgt))\n",
    "        num_poision = round((percent_poison * n_points_in_tgt) / (1 - percent_poison))\n",
    "\n",
    "        src_imgs = X_clean[y_clean == src]\n",
    "\n",
    "        n_points_in_src = np.shape(src_imgs)[0]\n",
    "        indices_to_be_poisoned = np.random.choice(n_points_in_src, num_poision)\n",
    "\n",
    "        imgs_to_be_poisoned = np.copy(src_imgs[indices_to_be_poisoned])\n",
    "\n",
    "        attack = PoisoningAttackBackdoor(add_modification)\n",
    "\n",
    "        imgs_to_be_poisoned, poison_labels = \\\n",
    "            attack.poison(imgs_to_be_poisoned, y=np.ones(num_poision) * tgt)\n",
    "        \n",
    "        X_poison = np.append(X_poison, imgs_to_be_poisoned, axis=0)\n",
    "        y_poison = np.append(y_poison, poison_labels, axis=0)\n",
    "        is_poison = np.append(is_poison, np.ones(num_poision))\n",
    "\n",
    "    is_poison = is_poison != 0\n",
    "\n",
    "    return is_poison, X_poison, y_poison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_poison = .33\n",
    "\n",
    "(is_poison_train, X_poisoned_train_raw, y_poisoned_train_raw) = \\\n",
    "    poison_dataset(X_train_raw, y_train_raw, percent_poison, add_modification)\n",
    "X_train, y_train = preprocess(X_poisoned_train_raw, y_poisoned_train_raw)\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "(is_poison_test, X_poisoned_test_raw, y_poisoned_test_raw) = \\\n",
    "    poison_dataset(X_test_raw, y_test_raw, percent_poison, add_modification)\n",
    "X_test, y_test = preprocess(X_poisoned_test_raw, y_poisoned_test_raw)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "n_train = len(y_train)\n",
    "shuffle_indices = np.arange(n_train)\n",
    "np.random.shuffle(shuffle_indices)\n",
    "X_train = X_train[shuffle_indices]\n",
    "y_train = y_train[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "model.compile()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = categorical_crossentropy\n",
    "optimizer = Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_classifier = TensorFlowV2Classifier(model=model, clip_values=(min_pixel_value, max_pixel_value), nb_classes=nb_classes, input_shape=(28, 28, 1), loss_object=loss_object, optimizer=optimizer)\n",
    "victim_classifier.fit(X_train, y_train, batch_size=128, nb_epochs=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_X_test = X_test[is_poison_test == 0]\n",
    "clean_y_test = y_test[is_poison_test == 0]\n",
    "\n",
    "clearn_preds = victim_classifier.predict(clean_X_test)\n",
    "acc = np.sum(np.argmax(clearn_preds, axis=1) == np.argmax(clean_y_test, axis=1)) / len(clean_y_test)\n",
    "print(f\"Clean test set accuracy: {acc * 100:.5f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_X_test = X_test[is_poison_test]\n",
    "poison_y_test = y_test[is_poison_test]\n",
    "\n",
    "poison_preds = victim_classifier.predict(poison_X_test)\n",
    "acc = np.sum(np.argmax(poison_preds, axis=1) == np.argmax(poison_y_test, axis=1)) / len(poison_y_test)\n",
    "print(f\"Poison test set accuracy: {acc * 100:.5f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_correct = np.sum(np.argmax(clearn_preds, axis=1) == np.argmax(clean_y_test, axis=1))\n",
    "poison_correct = np.sum(np.argmax(poison_preds, axis=1) == np.argmax(poison_y_test, axis=1))\n",
    "total_correct = clean_correct + poison_correct\n",
    "total = len(clean_y_test) + len(poison_y_test)\n",
    "total_acc = total_correct / total\n",
    "print(f\"Overall test set accuracy: {total_acc * 100:.5f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "i = 0\n",
    "\n",
    "c_idx = np.where(np.argmax(poison_y_test, axis=1) == c)[0][i]\n",
    "\n",
    "plt.imshow(poison_X_test[c_idx].squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Prediction: {}'.format(np.argmax(poison_preds[c_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Clustering\n",
    "<p style=\"color: red\">Kerasのバージョンが3になったことによる問題が発生していると考えられる為、割愛</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defence = ActivationDefence(victim_classifier, X_train, y_train)\n",
    "report, is_clean_lst = defence.detect_poison(nb_clusters=2, nb_dims=10, reduce='PCA')\n",
    "[clusters_by_class, _] = defence.cluster_activations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
